<!-- Company GitHub Profile README -->

<h1 align="center">Alessandro (Alex) Palmas</h1>

<p align="center">
  <b>Senior AI / ML Research Engineer · LawZero</b><br>
  Foundation Models · Reinforcement Learning · Alignment & Safety
</p>

---

### Role & Focus

I’m part of the **core research and engineering team at [LawZero](https://lawzero.org/en)**, a non-profit AI research lab in Montreal led by Yoshua Bengio.

My work focuses on advancing **foundation models that are truthful, transparent, and safe-by-design** — systems that *understand and reason about the world*, rather than merely act within it.

I operate at the intersection of **deep research and large-scale engineering**, helping bridge theoretical advances with practical, scalable implementations across reasoning, alignment, and interpretability.

Currently, my work includes:

- Large-scale, distributed **reinforcement learning finetuning** of foundation models  
- **Verifiable reward** formulations for code-focused LLMs  
- Building hands-on expertise in **RL applied to foundation models**, from experimentation to production-scale pipelines  

---

### This GitHub Profile

This profile is primarily used for **company-related research, experimentation, and engineering work**.

Personal projects, background, and broader interests are available via the GitHub sidebar and linked profiles.

---

<!-- Optional: selected repositories can be pinned directly on GitHub -->
